# kafka-final

## Инструкция по запуску

1. Создать в корне .env
    ```
    DATABASE_DSN=
    PRODUCT_TOPIC=
    PRODUCT_WITH_FULL_IMG_SET_TOPIC=
    PRODUCT_FILTERED_TOPIC=
    PRODUCT_FIND_TOPIC=
    SCHEMA_REGISTRY_URL=
    KAFKA_BROKERS=
    ```

2. Подготовка окружения docker

    ```bash
    make up
    ```

3. Создание топиков
    ```bash
    make create-topics
    ```
    **shop_products** - топик, куда магазины выгружают все товары
    **analytic_products_filtered** - топик, где пакетно отфильтрованы товары по названию
    **analytic_products_find** - топик, куда попадают промты поиска от пользователей

4. Созадания DEBEZIUM коннекторов для репликации топиков в postgres db
    ```bash
    make create-connectors
    ```
   
5. Создание миграций для аналитики ksqlDB
    ```bash
    make ksqldb-migration
    ```
    ***personal_recom*** - топик, агрегирующий в промты поиска с отфильтрованным списком товаров, как рекомендации для пользователя

## Структура проекта

    .
    ├── cmd                  # Основное приложение
    ├── docker               # KSQL скрипты и параметры коннектора
    ├── grafana              # параметры дашбордов/алертов графаны
    ├── internal             # Внутренний код
    │   ├── application      # Application layer
    │   ├── domain           # Domain layer
    │   ├── infra            # Infrastructure layer
    │   │   ├── config         
    │   │   ├── di
    │   │   └── msg          # процессоры / эмиттеры для Goka / schemaRegistry
    └── ...

## Инструменты
1. **zookeeper** для координации брокеров
2. **kafka** в качестве брокера сообщений
3. **schema-registry** для контроля над схемой сообщений
4. **debezium/connect** для репликации сообщений в БД
5. **ksqldb-server** для сбора аналитики из потока сообщений без написания кода
6. **ksqldb-cli** клиент для тестирования запросов ksqldb-server
7. **akhq** для тестирования и просмотра сообщений / статуса брокеров
8. **postgres** в качестве БД
9. **prometheus** для сбора телеметрии о состоянии брокеров
10. **grafana** для агрегации аналитики от prometheus и алертов
11. **go + goka** для реализации ShopApi, клиента для запросов товара, потоковой обработки/фильтрации сообщений от магазинов

## Реализация

Система имеет 3 точки входа:
1. **shop** - эмулирует работу магазинов. Отправляет заданное число сообщений с товарами в топик **shop_products** со случайными данными.
2. **stream** - потоково при помощи Goka процессора фильтрует сообщения из **shop_products** и помещает отфильтрованные в **analytic_products_filtered**.
Фильтрация происходит по наличию подстроки в названии товара. По-умолчанию при запуске подстрока для фильтрации пуста, тоесть проходят все товары.
Подстроку можно указать в терминале. После применения, каждое новое сообщение будет отфильтровано. В процессе работы подстроку можно поменять.
3. **client** - приложение ожидает от пользователя строки для поиска товара. После получения строки, она попадает в **analytic_products_find***.
В топике ***personal_recom*** при помощи ksqldb агрегируются рекомендации при полном совпадении промта поиска и названия товара.